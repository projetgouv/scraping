import streamlit as st
import pandas as pd
st.set_page_config(page_title='France Echanges', layout='wide')


# Titre
st.markdown("<h1 style='text-align: center;'>üá´üá∑ France √âchanges construisons ensemble France Travail</h1>", unsafe_allow_html=True)
st.markdown("<h2 style='text-align: center;'>France √âchanges, un projet innovant qui vise √† am√©liorer les services publics de l'emploi et de l'insertion professionnelle</h2>", unsafe_allow_html=True)
st.markdown("<br>", unsafe_allow_html=True)
st.error("Ce projet est r√©alis√© dans le cadre d'un partenariat p√©gagogique entre Service Public + et HETIC. L'entit√© France Echanges est fictive et les donn√©es utilis√©es sont des donn√©es publiques.", icon='‚õîÔ∏è')
st.warning("Nous avons rencontr√© quelques probl√®mes techniques, avec des donn√©es qui n'ont pas √©t√© int√©gralement extraites lors du scraping.", icon='‚ÑπÔ∏è')

st.markdown("<br>", unsafe_allow_html=True)
st.write("Dans la lign√©e du Service Public +, o√π l'innovation technologique et l'utilisation des donn√©es sont au c≈ìur du progr√®s des insitutions, le projet novateur **France √âchanges** exploite les avis Google d√©pos√©s sur les fiches P√¥le Emploi. Gr√¢ce √† des techniques de traitement automatique du langage naturel (NLP), nous analysons les commentaires des utilisateurs afin de comprendre leur verbatim, de mettre en √©vidence les reproches fr√©quents et d'identifier les aspects qui fonctionnent bien et ceux qui posent probl√®me.")
st.write("Pour mener √† bien ce projet, nous utilisons des technologies avanc√©es de NLP: l'**analyse des sentiments** et **topic modelling**  (BERTopic). Nous utilisons √©galement la **visualisation de donn√©es** pour pr√©senter les r√©sultats de notre analyse.")
